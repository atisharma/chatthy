# chatthy

An asynchronous terminal server/multiple-client setup for conducting and managing chats with LLMs.

- [x] can switch between Anthropic, OpenAI, tabbyAPI providers and models
- [x] client/server RPC-type architecture
- [x] message signing
- [x] basic chat persistence and management
- [x] streaming
- [x] syntax highlighting
- [x] switch system prompts
- [ ] select from saved system prompts (personalities)
- [x] decent REPL
- [x] REPL command mode
- [ ] cut/select from output
- [ ] inject from file
- [ ] templates for standard instruction requests
- [ ] integrate with other things like RAG / vdb
- [ ] tools
- [ ] chat editing
- [ ] chat truncation
- [ ] use proper config dir
- [ ] dump default conf if missing
- [ ] latex rendering (this is tricky in the context of prompt-toolkit, but see flatlatex)
